# 微分の基礎

1. 微分と関数最小化の関係

    関数が最小(最大)値を取る際の、接線は傾きが0になる

1. 2点間を通る直線の傾き

    a = (f(x2) - f(x1)) / (x2 - x1)

1. 接点の傾き

    点x1における接線の傾きを求めるために、もう一方の点x2をx1に近づけていきます。ただし、x1とx2が完全に同じになってしまうと、x方向、y方向の増加量がどちらも 0になってしまうため、傾きは 0/0で計算することができません。そこで2点は異なる点でありつつ、x2を限りなくx1に近づけていった時、直線の傾きがどのように振る舞うかを見る必要があります。  
    これを数学的に表現するには**極限**の考え方が必要となります。

    ```導関数
    f'(x) = (h->0)lim(f(x+h)-f(x)) / h
    df(x) / dx
    ここでdは増分を取る
    ex. dxはxの変化量
    ```

1. 微分の公式

    ```公式
    (x^n)' = nx^(n-1)
    (e^(ax))' = ae^(ax)・・・(8)
    ```

    ここでaは定数、eは自然対数の底、もしくはネイピア数と呼ばれる特別な定数。

    ```(8)
    (exp(ax))' = a*exp(ax)
    ```

1. 線形性

    微分は線型性という性質を持っています。
    微分には線型性という性質によって

    ```線形性
    (3x)' = 3 * (x)'
    ```

    定数項を演算の外側に出すことができる。また、

    ```線形性2
    (3x^2+4x-5)' = (3x^2)'+(4x)'-(5)'
    ```

    のように、加算や原産はそれぞれ項ごとに独立に微分の演算を行える。  
    ***この二つの特性を合わせて線形性と呼びます。***

1. 合成関数の微分

    ディープラーニングで用いるニューラルネットワークは、層を何層も重ねて複雑な関数を表現します。各々の層を1つの関数とみなすと、ニューラルネットワークは多くの関数（層）を合成した合成関数と見ることができます。

    ```連鎖律
    {(3x+4)^2}' = 2(3x+4)(3)
    df(g(x))/dx = (df(u)/du)*(du/dx)
    ```

1. 偏微分
    機械学習では、1つの入力変数xから出力変数yを予測するケースは稀であり、多くの場合、複数の入力変数x1,x2,…,xMを用いてyを予測する多変数関数が扱われます。  
    複数の入力x1,x2,…,xMをとる関数f(x1,x2,…,xM)を多変数関数という。  
    このような多変数関数において、ある1つの入力変数に着目して微分を行うことを偏微分という。

    ```偏微分
    ∂f(x1,x2,…,xM) / ∂xm
    ```

    ∂はデルと呼ばれる記号で、偏微分を表す。  
    ∂/∂xmはxm以外を定数と考え、xmにのみ着目して微分を行うという意味となります。
